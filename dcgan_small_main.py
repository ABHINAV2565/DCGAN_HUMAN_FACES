# -*- coding: utf-8 -*-
"""DCGAN_SMALL_MAIN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1trhu59zBE2XDYXkJzzO9I1xj4Os2HtAq
"""

import torch
print("GPU Available:", torch.cuda.is_available())

from google.colab import drive
drive.mount('/content/drive')

import torch
import torchvision
import matplotlib
import numpy

print(torch.__version__)
print(torchvision.__version__)
print(matplotlib.__version__)
print(numpy.__version__)

import os
import torch
import numpy as np
import matplotlib.pyplot as plt
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import pickle as pkl
from torchvision import datasets as dset
import zipfile, shutil

# Unzip dataset
with zipfile.ZipFile('/content/drive/MyDrive/TEAM_C4/celebdataset_small.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/celeba_raw')

# Create structure for ImageFolder
os.makedirs('/content/celeba/faces', exist_ok=True)

# Move images safely
for root, _, files in os.walk('/content/celeba_raw'):
    for file in files:
        if file.endswith('.jpg'):
            src_path = os.path.join(root, file)
            dst_path = os.path.join('/content/celeba/faces', file)
            if not os.path.exists(dst_path):
                shutil.move(src_path, dst_path)

# Data loader function
def get_dataloader(batch_size, image_size, data_dir='/content/celeba'):
    dataset = dset.ImageFolder(root=data_dir,
                               transform=transforms.Compose([
                                   transforms.Resize((image_size, image_size)),
                                   transforms.ToTensor(),
                               ]))
    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)

# Set hyperparameters
batch_size = 16
img_size = 128
celeba_train_loader = get_dataloader(batch_size, img_size)

# Function to display an image
def imshow(img):
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))

dataiter = iter(celeba_train_loader)
images, _ = next(dataiter)

# Scale function
def scale(x, feature_range=(-1, 1)):
    return x * (feature_range[1] - feature_range[0]) + feature_range[0]

scaled_img = scale(images[0])
print('Min:', scaled_img.min())
print('Max:', scaled_img.max())

# Define the Discriminator
class Discriminator(nn.Module):
    def __init__(self, conv_dim):
        super(Discriminator, self).__init__()
        self.conv1 = nn.Conv2d(3, conv_dim, 4, stride=2, padding=1)
        self.conv2 = nn.Conv2d(conv_dim, conv_dim * 2, 4, stride=2, padding=1)
        self.conv3 = nn.Conv2d(conv_dim * 2, conv_dim * 4, 4, stride=2, padding=1)
        self.conv4 = nn.Conv2d(conv_dim * 4, conv_dim * 8, 4, stride=2, padding=1)
        self.final_feat_map_size = 128 // (2 ** 4)
        self.fc = nn.Linear(conv_dim * 8 * self.final_feat_map_size ** 2, 1)

    def forward(self, x):
        x = F.leaky_relu(self.conv1(x), 0.2)
        x = F.leaky_relu(self.conv2(x), 0.2)
        x = F.leaky_relu(self.conv3(x), 0.2)
        x = F.leaky_relu(self.conv4(x), 0.2)
        x = x.view(x.size(0), -1)
        return self.fc(x)

# Define the Generator
class Generator(nn.Module):
    def __init__(self, z_size, conv_dim):
        super(Generator, self).__init__()
        self.conv_dim = conv_dim
        self.fc = nn.Linear(z_size, conv_dim * 8 * 8 * 8)
        self.tconv1 = nn.ConvTranspose2d(conv_dim * 8, conv_dim * 4, 4, stride=2, padding=1)
        self.tconv2 = nn.ConvTranspose2d(conv_dim * 4, conv_dim * 2, 4, stride=2, padding=1)
        self.tconv3 = nn.ConvTranspose2d(conv_dim * 2, conv_dim, 4, stride=2, padding=1)
        self.tconv4 = nn.ConvTranspose2d(conv_dim, 3, 4, stride=2, padding=1)

    def forward(self, x):
        x = self.fc(x)
        x = x.view(-1, self.conv_dim * 8, 8, 8)
        x = F.relu(self.tconv1(x))
        x = F.relu(self.tconv2(x))
        x = F.relu(self.tconv3(x))
        return torch.tanh(self.tconv4(x))

# Loss functions
def real_loss(D_out):
    criterion = nn.BCEWithLogitsLoss()
    labels = torch.ones(D_out.size(0), device=D_out.device) * 0.9
    return criterion(D_out.squeeze(), labels)

def fake_loss(D_out):
    criterion = nn.BCEWithLogitsLoss()
    labels = torch.zeros(D_out.size(0), device=D_out.device)
    return criterion(D_out.squeeze(), labels)

# Device setup
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Initialize models
z_size = 100
conv_dim = 64
D = Discriminator(conv_dim).to(device)
G = Generator(z_size, conv_dim).to(device)

# Optimizers
d_optimizer = optim.Adam(D.parameters(), 0.0002, betas=(0.5, 0.999))
g_optimizer = optim.Adam(G.parameters(), 0.0002, betas=(0.5, 0.999))

# Training loop
num_epochs = 50
fixed_z = torch.randn(16, z_size).to(device)

for epoch in range(num_epochs):
    for real_images, _ in celeba_train_loader:
        real_images = real_images.to(device)
        batch_size = real_images.size(0)

        # Train Discriminator
        d_optimizer.zero_grad()
        D_real = D(real_images)
        d_real_loss = real_loss(D_real)

        z = torch.randn(batch_size, z_size).to(device)
        fake_images = G(z)
        D_fake = D(fake_images)
        d_fake_loss = fake_loss(D_fake)

        d_loss = d_real_loss + d_fake_loss
        d_loss.backward()
        d_optimizer.step()

        # Train Generator
        g_optimizer.zero_grad()
        z = torch.randn(batch_size, z_size).to(device)
        fake_images = G(z)
        D_fake = D(fake_images)
        g_loss = real_loss(D_fake)
        g_loss.backward()
        g_optimizer.step()

    print(f"Epoch [{epoch + 1}/{num_epochs}] | d_loss: {d_loss.item():.4f} | g_loss: {g_loss.item():.4f}")

# Save models
torch.save(G.state_dict(), 'generator.pth')
torch.save(D.state_dict(), 'discriminator.pth')

# Generate and display images separately
G.eval()
with torch.no_grad():
    fake_images = G(fixed_z).cpu()

fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(6, 12))

# Input image
axes[0].imshow(np.transpose(images[0].numpy(), (1, 2, 0)))
axes[0].set_title("Input Image")
axes[0].axis('off')

# Generated image
axes[1].imshow(np.transpose(fake_images[0].numpy(), (1, 2, 0)))
axes[1].set_title("Generated Image")
axes[1].axis('off')

plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Define the number of images to display
num_images = 10  # Fixed to show exactly 10 input-output pairs

fig, axes = plt.subplots(2, num_images, figsize=(num_images * 2, 4))

for i in range(num_images):
    # Input images
    axes[0, i].imshow(np.transpose(images[i].numpy(), (1, 2, 0)))
    axes[0, i].set_title(f"Input {i+1}")
    axes[0, i].axis('off')

    # Generated images
    axes[1, i].imshow(np.transpose(fake_images[i].numpy(), (1, 2, 0)))
    axes[1, i].set_title(f"Generated {i+1}")
    axes[1, i].axis('off')

plt.tight_layout()
plt.show()

from google.colab import files
files.download('generator.pth')